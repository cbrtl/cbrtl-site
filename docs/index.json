[{"content":"What is cbrtl? cbrtl is an attempt at creating a tight knit group of programmers to showcase and collaborate on fun projects.\nWhat do we do here? Create fun projects. Either in groups or in isolation. Organize community and online showcases for group and individual projects. Contribute to Open Source projects both in cbrtl and in other communities. Conduct code reviews and JAMs. Share resources to learn. Create and maintain dev-journals and blogs. What is the end goal? Merely to promote Open Source culture and proper software development\nHow far down the road are we? Not that far, the egg has just been laid. As of the time of writing this post, we have just started out. For the effort to work out, we welcome interested folks over :)\nWhat can I do? Just what you\u0026rsquo;ve been doing so far, but with more people!\nIf you have any interesting projects that you have already been working on, let us know and we\u0026rsquo;ll put them on the cbrtl page for more people to see. Note that there is some criteria that projects must qualify, some of these are intentionally vague. But as long as you\u0026rsquo;re doing more than following a course or tutorial, it\u0026rsquo;s likely to be accepted :)\nVolunteering to cbrtl We are looking for volunteers for some roles. Note however, that there is no strict mandate for responsibilities. As long as you\u0026rsquo;re capable of adding something of value, no matter how small, shoot us a message! We\u0026rsquo;re looking for some help with:\nCode reviewers: If you have experience contributing to FOSS or writing code for user/developer facing products, perhaps you can volunteer and help us out here :)\nEditors: We plan on writing frequent blog posts. But both the technical content and the english material can use a second pair of eyes to help catch mistakes or inconsistent writing. If you have done some technical writing before, you can volunteer for reviewing the content in blog posts!\nTechnical Writers: If you have experience writing code but are usually on a tight schedule, you may be able to join us and share your knowledge. We want to mandate a high quality in our posts, so any tutorial/how-to guide that has been done a million times before is generally discouraged. We want to avoid redundant topics like \u0026ldquo;How to build a todo app with React\u0026rdquo; and promote posts and dev-logs / journals that are fun to read and explore.\nFrontend devs: Currently, the cbrtl website is bland and not-so-catchy. While minimalism is the core idea, we can definitely use some front-end developers to help keep the UI fresh, responsive and modern.\nModerators: To help keep the community together on discord and github.\nNOTE We do not expect any amount of time commitment from volunteers, as long as you can make small contributions, we appreciate it. Volunteering is not druge work, and active frequent contributions are appreciated, but not required.\nThe kind of software we want to write We firmly believe in re-inventing the wheel. Writing software close to the metal helps us closely understand the behind-the-scenes of software that most take for granted. While any creative project is welcome, here are some ideas that adhere to the spirit:\nCompilers Virtual Machines and Interpreters Game Engines Operating Systems Search Engines Database engines Voxel renderers TCP/IP stack VCS Web servers Web browsers Text editors Anything else that is NOT a react todo app, or a vue planner app, or a terminal tic-tac-toe game. All of these are but regular software that we tend to take for granted, that can be (and have been) written from scratch. We encourage all kinds of creative projects no matter how basic. But you can expect the above group projects to come to life as the community grows.\nShowcasing your project If you want to showcase your project on our github org, then reach out to us on discord or the mailing list.\n","permalink":"https://cbrtl.github.io/posts/what-and-why/","summary":"What is cbrtl? cbrtl is an attempt at creating a tight knit group of programmers to showcase and collaborate on fun projects.\nWhat do we do here? Create fun projects. Either in groups or in isolation. Organize community and online showcases for group and individual projects. Contribute to Open Source projects both in cbrtl and in other communities. Conduct code reviews and JAMs. Share resources to learn. Create and maintain dev-journals and blogs.","title":"Hello world!"},{"content":" Abstract machines and the computational universe Automata theory is a branch of theoretical computer science that deals with abstract machines and the computational problems that can be solved using these machines. Automata are mathematical models of a machine that can perform certain computations. Essentialy, these are fundamental units of computation that can process input and produce output based on a set of rules. They are used to model and analyze computational systems, study the limits of computation, and explore the properties of formal languages(sets of strings of symbols that can be recognized by automata).\nFor example, this automaton can be thought of as a machine that processes input strings of 0s and 1s and produces an output based on a set of rules, such as:\n$f: {0, 1}^* \\rightarrow {0, 1}^*$\nwhere $f$ is a function that takes an input string of $0$s and $1$s and produces an output string of $0$s and $1$s, based on the following rules:\nIf the input string contains an odd number of 1s, the output string should be 1. If the input string contains an even number of 1s, the output string should be 0. This automaton can be represented as a state machine, with states representing the number of 1s seen so far and transitions based on the input symbols. The machine starts in an initial state and transitions between states based on the input symbols, eventually reaching a final state that determines the output.\nIn simpler terms, think of it this way: an automaton is the smallest part of a machine that can operate independently and perform a specific task. Breaking this unit further would lead us nowhere, as it is the smallest indivisible part of a machine that can perform a computation. Like, a gearbox in a car is an automaton that performs the task of changing gears, and it can\u0026rsquo;t be broken down further into smaller parts that perform any meaningful task.\nConway\u0026rsquo;s Game of Life Building on automata theory, cellular automata are computational systems used to model complex systems and nonlinear dynamics. They are made up of simple, identical units called cells that evolve in parallel at discrete time steps. The state of each cell is determined by the states of its neighbouring cells, and the cells update their states based on a set of rules. Cellular automata have been used to study a wide range of phenomena, including biological systems, physical processes, and social dynamics.\nA fascinating aspect of cellular automata is their ability to exhibit complex and unpredictable behaviour from simple rules that mimic real-life population dynamics. Conway\u0026rsquo;s Game of Life is a simple cellular automaton devised by the British mathematician John Horton Conway in 1970. It is a zero-player game, meaning that its evolution is determined by its initial state, requiring no further input. One interacts with the Game of Life by creating an initial configuration and observing how it evolves. Specifically, the game explores how simple rules governing individual cells can lead to emergent complexity and patterns over time, including stable structures, oscillating patterns, and even patterns that exhibit motion.\nA few rules govern the evolution of the game are as follows:\nAny live cell with fewer than two live neighbours dies, as if by underpopulation. --\u003e Any live cell with two or three live neighbours lives on to the next generation. --\u003e Any live cell with more than three live neighbours dies, as if by overpopulation. --\u003e Any dead cell with exactly three live neighbours becomes a live cell, as if by reproduction. --\u003e The game is played on a two-dimensional grid of cells, each of which can be in one of two states: alive or dead. The game proceeds in discrete steps, with each step representing a generation of cells. At each step, the game applies the rules to each cell in the grid simultaneously, updating the grid to reflect the new state of each cell based on its current state and the states of its neighbours.\nThe Game of Life in Action Reset Grid Speed Start Generations: 0\nTo start, design your initial configuration by clicking on the cells to toggle their state. Once you\u0026rsquo;re ready, click the \u0026ldquo;Start/Stop\u0026rdquo; button to watch the game evolve. You can pause the game at any time by clicking the \u0026ldquo;Stop\u0026rdquo; button, and clear the grid by clicking the \u0026ldquo;Clear\u0026rdquo; button.\nThe speed of the game can be adjusted by changing the speed slider. The game will evolve at a faster pace as the slider is moved to the right. The grid slider can be used to adjust the size of the grid, allowing for larger or smaller configurations.\nA Turing Complete Machine This might seem cool; just a game, right? It\u0026rsquo;s more interesting than that. To explain why, I would have to make your brain hurt a little bit more.\nAutomata like these can be classified into two main categories: finite automata( finite states, finite memory) and infinite automata(infinite states, infinite memory). For example, a finite automaton can be used to recognize whether a given input string is a valid email address or a phone number(A regular expression). Infinite automata are more complex and powerful. For example, an infinite automaton can be used to recognize whether a given input string is a valid programming language statement or a mathematical expression. (Compilers and interpreters). Game of Life is a prime example of an infinite automaton, as it can simulate complex systems and exhibit infinite states from a fixed configuration.\nFinite automata can be further classified into:\nDeterministic Finite Automata (DFA): A determined outcome for a given input. Non-Deterministic Finite Automata (NFA): Various outcomes for a given input. However, both DFA and NFA:\nOperate on a finite amount of memory (the states). Can only make decisions based on the current state and the immediate input. Cannot handle languages that require unbounded memory, like those involving nested structures or long-term dependencies. To solve these issues, a Pushdown Automaton (PDA) was introduced. A PDA is an automaton with a stack that can store an unbounded amount of memory. It can push and pop symbols onto the stack, allowing it to handle context-free languages( languages that can be described by context-free grammar; languages powerful enough to describe many programming language constructs, such as nested structures (e.g., balanced parentheses, if-else blocks)) that require more complex memory access. Simply put, a PDA can recognize languages that a DFA or NFA cannot, making it a more powerful model of computation.\nBear with me, this useless information will make sense in a bit; I promise. The concepts of FSMs lay the groundwork for understanding why this cellular automaton is such a fascinating piece of work by this brilliant British mathematician.\nHowever, a PDA still has limitations:\nThe stack provides memory, but it\u0026rsquo;s limited in structure (LIFO- Last in First Out). It can\u0026rsquo;t handle languages requiring more general or unbounded memory access. This led to the development of the Turing Machine, a theoretical model of computation that can simulate any algorithm or computation that can be performed by a digital computer. A Turing machine consists of an infinite tape divided into cells, a read/write head that can move left or right along the tape and a finite set of states. The machine can read the symbol on the current cell, write a new symbol, move the tape left or right, and change its state based on a set of rules.\nTuring Machine is the pinnacle of computation, as it laid the foundation for modern computers and computational theory. It can, in theory, solve any computational problem that can be solved by a digital computer, making it a universal model of computation. Whatever we see today, from the smallest microcontroller to the most powerful supercomputers, satelite systems, and AI, all are based on the principles of the Turing Machine.\nThe Game of Life has been shown to be Turing complete, meaning it can simulate any computation that a Turing machine can perform, given the right initial conditions. Certain configurations in the Game of Life can be used to simulate logic gates, memory, and other components of a computer, demonstrating its computational universality and performing universal computation, making it a fascinating area of study for computer scientists and mathematicians alike. It has been studied extensively by computer scientists, mathematicians, and physicists, and has been used to explore a wide range of topics, including complexity theory, artificial life, and emergent behaviour.\nBuilding A CPU in the Game of Life Having come this far, let\u0026rsquo;s attempt to build a CPU in the Game of Life. A CPU essentially is built up of three main components:\nALU (Arithmetic Logic Unit): Performs arithmetic and logical operations on data. Memory: Stores data and instructions that are currently being executed by the CPU. Control Unit: Manages the CPU\u0026rsquo;s operations by directing data between the ALU, memory, and I/O devices. Arithmetic Logic Unit The ALU is responsible for performing arithmetic and logical operations on data. It consists of a number of logic gates, adders, and other components that work together to perform operations such as addition, subtraction, AND, OR, and NOT. Adder Circuit AND Gate In addition, you can set up a glider collision that represents the addition of two binary values. Each glider can be thought of as representing a binary input (either 0 or 1). The gliders in this pattern are designed to approach each other from opposite directions. When two gliders collide, they interact to produce an output, which can be interpreted as the sum of the two inputs. This collision represents the addition of two binary values, with the output glider moving in a different direction depending on the inputs.\nIf only one glider is present (input 1 + 0 or 0 + 1), it moves through without a collision, representing a result of 1. If two gliders collide (input 1 + 1), they create a predictable pattern that can represent the sum of these inputs, often leaving behind a specific \u0026ldquo;output\u0026rdquo; glider that can represent the result. Similarly, An AND gate can be created by positioning still-life patterns (static configurations that do not change) to manipulate gliders. If both inputs are \u0026ldquo;1\u0026rdquo; (represented by gliders arriving simultenously), they will interact to produce an output.\nIf both gliders arrive at the interaction point simultaneously, they will interact in a way that produces a specific pattern, representing the output 1 for an AND operation. If only one glider arrives, it will pass through or interact with other cells without producing the 1 pattern, representing an output of 0. Memory Unit Memory Unit stores data and instructions that are currently being executed by the CPU. It consists of registers, cache, and main memory. It is responsible for storing and retrieving data from memory locations.\nBlinker Memory Cell(1 block) This configuration is a 3x3 blinker, which oscillates between two shapes in two generations. Its oscillation does not spread or decay, so it remains contained and stable in its oscillating state.\nMemory can be represented by stable patterns that remain constant unless disturbed by an external glider or oscillator. Stable patterns like blocks act as \u0026ldquo;bits\u0026rdquo; that can be toggled on or off by gliders, representing data storage. These two states can represent binary values (0 and 1) in a very simplistic way, with each state encoding one bit of information depending on its phase. This stability in position and periodic change makes it suitable for acting as a memory cell, as it reliably returns to a known state every two generations.\nSimilarly, an external pattern could be designed to change or \u0026ldquo;write\u0026rdquo; to the memory cell, altering its oscillation phase to represent a different binary state.\nControl Unit The control unit manages the CPU\u0026rsquo;s operations by directing data between the ALU, memory, and I/O devices. It fetches and decodes instructions, then signals the ALU and memory to execute. Control Unit This pattern is designed to function as a control unit by leveraging the behavior of known oscillators and spaceships in the Game of Life to produce predictable and repeatable outcomes. The pattern includes configurations that will evolve into gliders, which are small patterns that move across the grid over successive generations. Gliders can be used to transmit information or interact with other patterns in the grid.\nGlider gun A glider gun is a configuration of cells that emits gliders at regular intervals. It can be used to create a clock signal that controls the timing of operations in the CPU.\nGlider Gun A single block here can represent \u0026lsquo;1\u0026rsquo; and an empty cell can represent \u0026lsquo;0\u0026rsquo;. The glider gun emits gliders at regular intervals, which can be used to synchronize the operations of the CPU. These inputs can work with adders, logic gates, and memory cells to perform ALU operations, store data, and control the flow of information within the CPU.\nA Fully Functional Computer To build a fully functional computer, you would need to design and implement a wide range of components, including registers, multiplexers, and arithmetic logic units, and connect them to form a complete system. Some of the components you would need to build include:\nALU components:\nAdders (Half and Full- they can be used to add binary numbers) ⏎ Logic Gates (AND, OR, NOT, XOR, etc.- they perform logical operations on binary inputs) ⏎ Multiplexers( MUX- they select one of many inputs and route it to the output, used to handle multiple data inputs and control signals) Registers( they store data temporarily during processing and can be used to store intermediate results) Memory components:\nFlip-Flops (they store a single bit of data using feedback) ⏎ RAM (Random Access Memory- they store data that can be read and written to used for storing data and instructions specific to the program) ROM (Read-Only Memory- they store data that can only be read from- used for storing fixed data and instructions that do not change) Control Unit components:\nFinite State Machines (FSM- they have a finite number of states and transition between states based on inputs) ⏎ Clock Signals (they provide a timing mechanism for the CPU, controlling the rate at which operations are performed- using glider guns) ⏎ Instruction Decoders (they interpret instructions and direct the flow of data within the CPU) Next While it is theoretically possible to build a computer within the Game of Life, it is painstakingly complex and fun! It requires a deeper understanding of logic gates, instruction sets, implementing memory, and control units.\nBuilding the CPU would take you to combine these components to carry out fully functional operations. It would be a fun and challenging project to undertake, requiring a deep understanding of digital logic and computer architecture. The Game of Life serves as a fascinating model of how complexity can arise from simplicity, providing insight into topics such as self-organization, emergence, and cellular automata theory.\nHere\u0026rsquo;s an actual CPU built in the Game of Life by Nicholas Carlini. In this series of posts, he tries to explain how he built digital logic gates, multiplexers, and registers in the Game of Life. I would love to do this someday when NYU is not down my throat threatening to kick me out for not doing my assignments.\nIf you choose carefully enough, you can make an entire computer inside the game, powered entirely by little things running around based only on those same simple rules of what lives and what dies in the next generation. An entire computer that could, in theory, perform any calculation that your computer could. It\u0026rsquo;s an interesting mathematical diversion depicting Turing\u0026rsquo;s completeness, the chaos that arises from simple rules, and it just looks pretty.\u0026quot;\n- Reddit\nAlso, someone built a Game of Life inside a computer built on top of THE GAME OF LIFE!!\n","permalink":"https://cbrtl.github.io/posts/game-of-life/","summary":"Abstract machines and the computational universe Automata theory is a branch of theoretical computer science that deals with abstract machines and the computational problems that can be solved using these machines. Automata are mathematical models of a machine that can perform certain computations. Essentialy, these are fundamental units of computation that can process input and produce output based on a set of rules. They are used to model and analyze computational systems, study the limits of computation, and explore the properties of formal languages(sets of strings of symbols that can be recognized by automata).","title":"Conway's Game of Life"},{"content":" NOTE: This blog post is taken from injuly\u0026rsquo;s website\nTry drawing something on the first canvas, and watch two sets of mechanical alien arms retrace your sketch:\nOnce you\u0026rsquo;re done with this introduction to Fourier analysis, you\u0026rsquo;ll be capable of making this (and a lot more) yourself.\nThe satisfying animation is made possible by the subject of this post - an infinite sum called the Fourier series. The formula is short, and with some effort, you can memorize it. However, I implore you to understand where the series comes from, and build deeper intuition for it.\nTo keep you from clicking off this page, I\u0026rsquo;ll defer the proof and origin of this equation to the second half, and thread some interactive animations through the body of this write-up.\nAdding functions Surely, you\u0026rsquo;re familiar with the addition of numbers, vectors and matrices. Adding functions is not so different. The addition of two functions \\(f\\) and \\(g\\) at input \\(x\\) is simply \\(f(x) + g(x)\\).\nPut more formally - \\((f + g)(x) = f(x) + g(x)\\).\nLet\u0026rsquo;s visualize this by taking an example. Assume f is \\(2sin(x)\\) and g is \\(cos(2x)\\).\nTheir sum then, can be given by a function - \\(h(x) = 2sin(x) + cos(2x)\\).\nThe graph below plots \\(f\\) and \\(g\\) in shades of gray, and their sum, \\(h\\), in red.\nNote how in some places, the values of \\(f\\) and \\(g\\) are both positive, and their sum is therefore a larger positive number, while in other places, \\(f\\) and \\(g\\) have opposite signs and their values cancel out to a smaller number.\nThrough the lens of physics, you could look at the functions as two electromagnetic waves, or just visible light rays oscillating in the domain of time. When two such waves overlap with each other in space, they\u0026rsquo;re said to be in superposition. The superposition of two waves results in the sum of both waves.\nWhen two points in a wave supplement each other to result in a higher amplitude (the y-value), their interaction is termed \u0026ldquo;constructive interference\u0026rdquo;. When they cancel each other out, it\u0026rsquo;s called \u0026ldquo;destructive interference\u0026rdquo;.\nGo through the last two paragraphs again, and try to digest this idea. Now, imagine if we had to work our way backwards. Say we are given a list containing the (x, y) coordinates of all points along the curve of \\(h\\), where \\(x\\) is time and \\(y\\) is the corresponding output of \\(h\\) at that point in time. We have to come up with two simpler periodic functions that sum up to \\(h\\).\nThis is exactly what the Fourier series does.\nThere are several ways to interpret interference in the real world. If \\(f\\) and \\(g\\) were sound waves, their constructive interference would make loud noise, while the destructive interference would produce a quieter sound. If they were light waves instead, their constructive interference would reveal bright spots on a reflective surface, and destructive would look like dim patches.\nApplications of the Fourier series spill into almost every domain - signal processing, image compression, shape recognition, analog transmission, noise cancellation, studying thermodynamic systems and fitting equations to datasets.\nFrom this wide array of applications, We show our interest in the science of tracing ugly sketches.\nDecomposing periodic functions. Imagine you had a machine that could scan any food item and display its recipe. Fourier series does exactly that, except for mathematical functions.\nThe Fourier series of any periodic function \\(f(x)\\) with a frequency of \\(\\omega_0\\) is described as:\n$$ f(x) = a_0/2 + \\sum_{n=1}^{\\infty}b_n sin(n\\omega_0x) + \\sum_{n=1}^{\\infty}a_n cos(n\\omega_0x) $$ Meaning that for every periodic function \\(f\\), there exists a set of coefficients \\(a\\) and \\(b\\), such that \\(f(x)\\) can be expressed as an infinite sum of sine and cosine terms of increasing frequencies where the \\(nth\\) sine term has a coefficient of \\(b_n\\) and the \\(nth\\) cosine term has a coefficient of \\(a_n\\). The values of these coefficients are given by the following formulae:\n$$ a_n = \\int_0^T{f(x)cos(nw_0x)} $$\n$$ b_n = \\int_0^T{f(x)sin(nw_0x)} $$\nThe interval of integration, \\(T\\), is the fundamental period of the function. \\(T\\) and \\(\\omega_0\\) are related by this equation:\n$$ \\omega_0 = 2\\pi/T $$\nIf that was too wordy and made little sense to you, that\u0026rsquo;s okay. We\u0026rsquo;ll prove this equation later in the post. Until then, an example will help understand this better.\nConsider the square wave - a periodic signal that alternates between 1 and -1 depending on its input. Formally, it is described like so:\n$$ f(t) = 4 \\lfloor{t}\\rfloor - 2\\lfloor2t\\rfloor + 1 $$\nHere\u0026rsquo;s how it looks when graphed out:\nIf we use the first few terms from \\(f\\)\u0026rsquo;s Fourier series, we can closely approximate the behavior of this function. In the following graph, the gray curve represents the the square wave and the red curve represents our approximation of it. You can play with the slider to alter the number of terms we take from the series and see how that changes our approximation.\nClearly, our approximation improves as we take more terms from the series. The Fourier series can be proven to converge. This means that if we take an infinite number of terms from the series, we can get the exact value of \\(f(x)\\) for any \\(x\\).\nOf course, it is not possible to add up infinite terms in computers. Instead, we decide upon a fixed number of terms that approximate our function well enough for most practical purposes.\nWhenever I say \u0026ldquo;Fourier series of a function\u0026rdquo;, I mean a series of simple periodic functions that can be added at any given input to approximate the output of the original function at the same input. For the remainder of this post our goal with Fourier series is to approximate periodic functions with sums of simpler sine/cosine functions.\nDrawing with the Fourier series If you wish to understand how the Fourier series works before seeing it in action, you can skip this section and read ahead to the proof, then come back here.\nSo, How do we go from decomposing time domain functions to recreating sketches?\nImagine you\u0026rsquo;re drawing a sketch on a square sheet of paper. You are to draw your sketch, start to finish, without lifting the nib of your pen from the paper\u0026rsquo;s surface. In other words, your sketch must be continuous with no \u0026ldquo;breaks\u0026rdquo; in between.\nAssume also that the bottom-left corner of the sheet is its origin. Once you start drawing, I can delineate the position of the pen\u0026rsquo;s tip using a pair of coordinates \\((x, y)\\) at any given point in time.\nMuch like a cartesian plane, the \\(x\\) coordinate represents the horizontal distance from the origin, and \\(y\\) the vertical. Both the x and y coordinates change as the pen moves on the sheet\u0026rsquo;s surface. Meaning, the position of the x-coordinate of your pen\u0026rsquo;s tip can be written as a function of time. Say you draw this figure:\nIf we plot the x and y-coordinates independently as functions of time, they\u0026rsquo;ll form curves that look like this:\nThe blue curve represents the values of x-coordinates of your sketch. The vertical axis represents the x-value, and the horizontal axis represents time. Similarly, the red curve plots the y-coordinates.\nBoth these curves can be viewed as functions of time. The blue curve represents a function \\(x(t)\\) that returns the x-position of the pen\u0026rsquo;s tip at time \\(t\\), Similarly, the red curve is a function \\(y(t)\\) which the same for its y-position. For each of these functions, we can find a Fourier series that approximates it.\nLet \\(f_x(t)\\) and \\(f_y(t)\\) be the Fourier approximations for \\(x(t)\\) and \\(y(t)\\) respectively. Then recreating the sketch requires computing the values returned by f_t and y_t over a range of values of t. then pairing them into (x, y) coordinates and connecting the coordinates with lines. Here is some pseudo-typescript code that mimics this logic:\n// The \u0026#34;dt\u0026#34; is our time step. // In the real world, a line is an infinitely long series of points. // In computers, we take a \u0026#34;snapshot\u0026#34; of the pen\u0026#39;s position // every dt seconds and join these positions with straight lines to // trace the curve. Smaller values of dt require more computation, // and yield better results. const dt = 0.01; const f_x = fourier_series(x); // type of x is (t: number) =\u0026gt; number const f_y = fourier_series(y); // type of y is (t: number) =\u0026gt; number let prev_point = [f_x(0), f_y(0)]; for (let t = 0.01; t \u0026lt; 1; t += dt) { const current_point = [f_x(t), f_y(t)]; draw_line(prev_point, current_point); prev_point = current_point; } The approximation generated by this method is shown below. Just as before, you can play with the slider to adjust the number of terms used in approximation of the sketch.\nKeep in mind that f_x and f_y are really just sums of simpler sine/cosine functions, calculated using Fourier\u0026rsquo;s formulae.\nYou may be wondering - the functions \\(x(t)\\) and \\(y(t)\\) aren\u0026rsquo;t periodic, how come we can still decompose them into sine/cosine sums? One trick is to set the period to infinity, and compute the series at this limit.\nIn my code, I just set the period to 1 time unit, and assume that the pen just retraces the drawing again and again. Meaning that \\(x(t + 1) = x(0)\\). This makes the math a lot easier, and certainly doesn\u0026rsquo;t make a difference in the outcome.\nTo be more clear, when the sketch starts, the time is assumed to be 0, and when it ends, the time is assumed to be 1 second. Every time point in between is scaled accordingly. This is not necessary of course, you could set the time period to however long it took to draw the first sketch, if that makes things simpler for you.\nEpicycles The final caveat are the epicycles. It is easy to just plot the values returned by \\(f_x\\) and \\(f_y\\) on the cartesian plane. But how do we animate this using revolving circles?\nIf you\u0026rsquo;ve followed the contents of this article so far, you already know how to recreate sketches. To animate them, you need to understand The polar coordinate system.\nYou can read the wikipedia article, or this article to build some intuition for conversion between cartesian and polar coordinates.\nIn the polar coordinate system, a periodic function with period \\(T\\) is a vector that rotates around the origin, and completes one full rotation around itself every \\(T\\) time units. Look at the graph of \\(sin(t)\\) in Polar form, for example:\nNote how the y-coordinates of the vector\u0026rsquo;s tip traces out a regular sine wave. You can just as easily plot any periodic function in the polar coordinate system. To add two periodic functions together, take one rotating vector and center it on the tip of the another rotating vector. The end result is shown below. The following animation shows 3 rotating vectors added together, each representing a periodic function:\nTo convert a sketch to an epicycle animation then, all we need is to convert a term in the Fourier series from cartesian to polar coordinates. Once we have that, we can add up the terms like in the animation above, and figure out the x and y-coordinates using two sets of epicycles, each representing the Fourier approximation for \\(x(t)\\) or \\(y(t)\\).\nTo do this conversion, we can use the polar form of the Fourier series. Precisely, these are the steps you need to follow:\nRepresent the sketch as a list of points drawn over a period of time. Convert the list of points into a two separate lists, one containing the x-coordinates of the sketch, and other the y. Convert each list into a function (I use this simple helper). Now, you have the \\(x(t)\\) and \\(y(t)\\). For each function, find its Fourier series coefficients. Here is how I do it. For each function, convert the Fourier series coefficients into a set of polar functions. Using a time step of dt, find the final x and y positions of our approximation, and draw them on a canvas. If you do everything correctly, you should get something like this:\nThere is a more novel approach to retracing sketches that involves using only one set of epicycles. It uses the complex Fourier Series, and is also fewer lines of code. When you\u0026rsquo;re new to this concept however, it may throw you off balance, especially if you\u0026rsquo;re not familiar with imaginary numbers and the Argand plane.\nProof When I set out to find an \u0026ldquo;intuitive\u0026rdquo; proof for the Fourier series, all I saw were proofs that begin by stating the equation, and then proving it by finding the coefficients \\(a_n\\) and \\(b_n\\) using integrals. But where did the equation come from?\nDid God whisper it to Joseph Fourier in his dreams?\nDid he just happen to run into it by chance?\nSurprisingly, the answer is \u0026ldquo;yes\u0026rdquo;. Of course, he had an unparalleled instinct for math that he whetted with years of practice and research. There has to be a certain train of thought that he boarded to arrive at this revelation, that any periodic signal can be represented as a sum of simpler harmonics. But that line of thinking was never publicized, and as you\u0026rsquo;ll see in the next section, there have been people who\u0026rsquo;ve thought of this even before Fourier himself did!\nThe important part is that Fourier asked a question that was mocked as stupid and bizarre until he presented a proof. And that proof does in fact begin by stating the following hypothesis:\n$$ f_o(t) = \\sum_{n = 0}^\\infty{b_nsin(n\\omega_0t)} $$\nHere, \\(f_o\\) is an odd function with a fundamental period of \\(w_0\\). If we can derive a value for \\(b_n\\) from this equation, we can be convinced that any odd function can be represented as a sum of sinusoids.\nNow, consider an even function \\(f_e\\) with a period of \\(w_0\\):\n$$ f_e(t) = \\sum_{n=0}^{\\infty}a_n cos(n w_0 t) $$\nIf we can derive a value for \\(a_n\\) from this equation, we can be convinced that any even function can be represented as a sum of co-sinusoids.\nWhen you combine these two equations with the idea that any periodic function can be represented as a sum of odd and an even function, you get:\n$$ f_o(t) + f_e(t) = \\sum_{n = 0}^\\infty{b_nsin(n\\omega_0t)} + \\sum_{n=0}^{\\infty}a_n cos(n w_0 t) $$\nWe can turn the order of this proof, and first say that given any function \\(f(t)\\), we can find its odd and even parts using the odd-even decomposition rule. Then, we can represent the odd part as a sum of sinusoids, and the even part as a sum of co-sinusoids.\nNow, all that\u0026rsquo;s left is to derive the values for \\(a_n\\) and \\(b_n\\) using the two equations stated above. This is where I save myself the trouble of writing more LaTeX, and defer you to this excellent proof by professors from Swarthmore college. I know I said I\u0026rsquo;d walk you through the proof, but I can\u0026rsquo;t do a better job of it than the electronics professors at Swarthmore did already. I\u0026rsquo;d hate to repeat their work and not give credit. If you follow the page I linked, you\u0026rsquo;ll realize that the proof only uses basic calculus and trigonometric identities taught in high school.\nOrigins You\u0026rsquo;ll be surprised to learn that the idea behind the series predates Fourier himself.\n2 centuries before Fourier, Carl Friedrich Gauss created several algorithms to aid his study of astronomy. He was one of the many applied mathematicians who wanted to predict the position of Ceres in the night sky. One of the algorithms he discovered in this quest, was the Fast Fourier Transform - a function that is very closely related with the Fourier Series. However, he never published his work because he believed his method to be an unimportant detail in his achievement of estimating Ceres\u0026rsquo; position.\nIn the 1700s, Euler had found applications for decomposing periodic functions with Fourier Series.\nHalf a century before Fourier, Bernoulli was studying the motion of a string. He proposed the idea that periodic functions can be represented as sums of harmonics. Nobody at the time believed this to be a general method, and his ideas were left unexplored.\nThings changed in 1807, when a French math wizard named Joseph Fourier found himself studying the heat equation in a metal plate. In his search for a solution, he sought to ask a seemingly absurd question:\nCan we represent any periodic function as a sum of simple sine and cosine functions?\nPrecisely, he sought to represent any periodic function \\(f(x)\\) with a frequency of \\(\\omega_0\\) , in the following form:\n$$ f(x) = (a_0 + a_1 cos(\\omega_0 t) + a_2 cos(2\\omega_0 t) + ... + a_n cos(n\\omega_0t)) + (b_1 sin(\\omega_0 t) + b_1 sin(2\\omega_0 t) + ... + b_n sin(n\\omega_0t) $$ Revered mathematicians of the time, including Langrange and Laplace, rejected this idea as informal and hand-wavy. The panel evaluating his findings said:\n\u0026ldquo;The manner in which the author arrives at these equations is not exempt of difficulties and\u0026hellip;his analysis to integrate them still leaves something to be desired on the score of generality and even rigour.\u0026rdquo; Perhaps this was because of a lack of reasoning as to why one should even begin to think of periodic functions this way.\nIt\u0026rsquo;s not unheard of mathematical ideas to sprout into existence out of seemingly ridiculous places. Ramanujan attributed some of his major findings to God, and dipped at the age of 32.\nAfter the Fourier Series was accepted by the scientific populace, it spawned a new field of research, called Fourier analysis. Developments in this field found everyday use in almost every science.\nApplications By this point, you know enough about Fourier analysis to delve deeper into it yourself. It would be a shame to blunt the edge of theory by not applying it in practice.\nHere a few things you could do:\nImplement noise reduction in sounds. Sharpen images with denoising. Write a JPEG encoder/decoder. Fit an elephant Write basic shape recognizers. Resources and further reading 3b1b - But what is a Fourier series?. Swarthmore college - The fourier series. Jez Swanson - An interactive introduction to the fourier transform. Tony Rosler - myFourierEpicycles ","permalink":"https://cbrtl.github.io/posts/fourier/","summary":"NOTE: This blog post is taken from injuly\u0026rsquo;s website\nTry drawing something on the first canvas, and watch two sets of mechanical alien arms retrace your sketch:\nOnce you\u0026rsquo;re done with this introduction to Fourier analysis, you\u0026rsquo;ll be capable of making this (and a lot more) yourself.\nThe satisfying animation is made possible by the subject of this post - an infinite sum called the Fourier series. The formula is short, and with some effort, you can memorize it.","title":"Fourier Series"}]